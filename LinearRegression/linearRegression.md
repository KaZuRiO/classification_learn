# üî¨ Exp√©rimentation ‚Äì Impact des Param√®tres sur la Pr√©cision (Accuracy)

Ce document d√©crit une s√©rie d‚Äôexp√©riences visant √† analyser l‚Äôimpact de diverses **modifications** (pr√©traitement, choix de param√®tres, etc.) sur la **pr√©cision du mod√®le de r√©gression logistique** utilis√© pour la classification d‚Äôimages thoraciques.

## ‚öôÔ∏è R√©glages de Base (Baseline)

| Param√®tre        | Valeur                                |
| ----------------- | ------------------------------------- |
| Mod√®le           | `LogisticRegression(max_iter=1000)` |
| Taille des images | `(400, 400)`                        |
| Mode              | `Grayscale`, aplatie                |
| Normalisation     | Pixels entre 0 et 1                   |
| Jeu de test       | 20% des donn√©es, stratifi√©          |

**Accuracy de base :** 86%

---

## üß™ Batterie de Tests

### üîÅ 1. Variation du pr√©traitement

| ID | Modification              | Description                                   | R√©sultat (Accuracy) |
| -- | ------------------------- | --------------------------------------------- | -------------------- |
| V1 | `image_size=(200, 200)` | R√©duction de la taille pour acc√©l√©rer      | 85%                  |
| V2 | `image_size=(100, 100)` | Compression agressive, possible perte d'infos | 87%                  |

---

### ‚öôÔ∏è 2. Modifications du mod√®le

Parametre de base: `image_size=(100, 100)`

| ID | Modification      | Description                                            | R√©sultat (Accuracy) |
| -- | ----------------- | ------------------------------------------------------ | -------------------- |
| M1 | `max_iter=2000` | Plus d‚Äôit√©rations pour convergence                   | 87%                  |
| M2 | `solver='saga'` | Meilleur pour grands datasets                          | 88%                  |
| M3 | `penalty='l1'`  | R√©gularisation L1 (sparse solutions)                  | 83%                  |
| M4 | `C=0.1`         | Plus forte r√©gularisation (moins de surapprentissage) | 86%                  |
| M5 | `C=10.0`        | Moins de r√©gularisation (plus de flexibilit√©)        | 87%                  |

---

## üìä R√©sum√© √† compl√©ter apr√®s chaque test

| Test ID | Accuracy | Observations                                               |
| ------- | -------- | ---------------------------------------------------------- |
| V1      | 85%      | R√©duction l√©g√®re du temps d'entra√Ænement, perte minime |
| V2      | 87%      | Accuracy d√©grad√©e, trop peu d'info dans les images       |
| M4      | 86%      | R√©gularisation trop forte ‚Üí sous-apprentissage           |

---

## üìå Recommandations

- Conserver les images en `400x400` ou r√©duire √† `200x200` max.
- Tester `C` entre `0.1` et `10.0` pour trouver un bon compromis.

---

üõ†Ô∏è Code type pour un test

```python
model = LogisticRegression(
    solver='saga',
    penalty='l1',
    C=0.5,
    max_iter=2000,
)
```
